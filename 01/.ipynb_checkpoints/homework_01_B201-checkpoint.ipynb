{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Homework - data visualisation and web scraping (deadline October 18th)\n",
    "\n",
    "  * In this homework you should download (*scrape*) data from the web, process it and visualise.\n",
    "  * The objective is to download data from server https://www.psp.cz/en/sqw/hlasovani.sqw?o=8 regarding voting in the Chamber of Deputies of the Parliament of the Czech Republic, save it in a tabular form and create visualisations, which make exploration of the data easier and show interesting information about it.\n",
    "\n",
    "> **Unfortunately, the web page is only in Czech. However, it should be possible to navigate it. Please contact your tutorial teacher in case of any questions.**\n",
    "\n",
    "## Data\n",
    "\n",
    " * Download data from all votings of the current Chamber of Deputies (since 2017). Download details of voting of particular deputies.\n",
    " * Data should contain basic information about the voting - number of meeting, number of voting, point of the meeting and date.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "> **Homework is assigned in a way that you have space for invention. Thinking of the _exact solution path_ is part of the assignment. Originality will be taken into account in the evaluation.**\n",
    "\n",
    "**Basic points of the assignment (8 points)**:\n",
    "  * Write Python script for downloading data. Download the data and save it in a suitable machine-readable format.\n",
    "  * **Wait at least 1 second between two consecutive requests to the server, to not overload it.**\n",
    "  * In the second part of the notebook, work with the data loaded from a local file. File(s) with downloaded data should be submitted as well (so the reviewer do not have to download the data again).\n",
    "  * Create visualisations to show the following:\n",
    "    * Deputies changing their parliamentary clubs.\n",
    "    * Attendance of individual deputies in the votings. Attendance of parliamentary clubs in the votings.\n",
    "    * How often individual parliamentary clubs vote the same and different.\n",
    "    * Are deputies in the same parliamentary club voting the same? Who are the biggest rebels?\n",
    "\n",
    "**Further points of assignment**, each for 2 points (maximum for the homework is 12):\n",
    "  * Visualise some time development in the data (e.g. attendance, change of agreement in voting among individual parliamentary clubs, etc.)\n",
    "  * Find individual deputies who have the most similar voting or attendance.\n",
    "  * Try to find particular voting, where deputies voted the most differently than traditionally.\n",
    "  \n",
    "## Tips and tricks\n",
    "  * Import libraries at the beginning of the notebook, or the beginning of scraping and visualisation parts.\n",
    "  * Use markdown cells (like this one) and headings to make orientation in the notebook easier.\n",
    "  * Select plots and visualisation matching the information you want to show. You can see galleries of libraries `matplotlib` and `seaborn` for inspiration.\n",
    "\n",
    "## Submission notes\n",
    "\n",
    "  * Follow instructions at https://courses.fit.cvut.cz/BIE-VZD/homeworks/index.html\n",
    "  * Submit **Jupyter Notebook** (possibly with additional scripts) and **file(s)** with downloaded data\n",
    "  * Reviewer may allow you to finish or correct your homework to achieve additional points. However, the first version is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import lxml.html\n",
    "\n",
    "\n",
    "class Deputy:\n",
    "    def __init__(self, name, id):\n",
    "        self.name = name\n",
    "        self.id = id\n",
    "        self.polit_group = []\n",
    "        self.member_from = []\n",
    "        self.generate_info()\n",
    "        \n",
    "#         self.list_of_votes = []\n",
    "#         create list of votes [yes, no , omluvlen]\n",
    "        \n",
    "    def generate_info(self):\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        self.url = str('https://public.psp.cz/en/sqw/detail.sqw?id=' + str(self.id) + '&o=8&l=cz')\n",
    "        r = requests.get(self.url)\n",
    "        soup = BeautifulSoup(r.content.decode('windows-1252', 'ignore'), 'html.parser')\n",
    "\n",
    "        lis = [i for i in soup.find_all('li') if 'Political group' in str(i)]\n",
    "        for content in lis:\n",
    "            self.polit_group.append(content.find('a').text)\n",
    "            member_from = str(str(str(content).split(' from ', 1)[1])[:-5]).replace('\\xa0', '')\n",
    "            if 'till ' in member_from:\n",
    "                member_from = member_from.split('till ', 1)[1]\n",
    "            self.member_from.append(member_from)\n",
    "        \n",
    "        \n",
    "    def load_to_csv(self, path):\n",
    "        out = str(self.name) + ';' + str(self.id) + ';' + str(self.polit_group) + ';' + str(self.member_from) + '\\n'\n",
    "        with open('deputy.csv', 'a') as file:\n",
    "            file.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_data(url, vote_df, deput_list, results_list):\n",
    "    # Step one\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content.decode('windows-1252', 'ignore'), 'html.parser')\n",
    "    ahrefs = []\n",
    "    \n",
    "    for link in soup.find_all('a'):\n",
    "        ahrefs.append(link.get('href'))\n",
    "    \n",
    "    meeting_links = []\n",
    "    url = 'https://public.psp.cz/en/sqw/'\n",
    "    \n",
    "    for elem in ahrefs:\n",
    "        if elem.startswith('hl.sqw?o=8&s=') and len(elem) <= 15:\n",
    "            meeting_links.append(url + elem)\n",
    "    # Step two\n",
    "    r = requests.get(meeting_links[0])\n",
    "    r.encoding=\"windows-1252\"\n",
    "    soup = BeautifulSoup(r.content, 'lxml')\n",
    "\n",
    "    # soup.find_all('a', href=re.compile(\"phlasa.sqw\"))  -> alternative\n",
    "    link = soup.select_one(\"a[href^='phlasa.sqw']\") \n",
    "    link = re.search(r'\"([^\"]*)\"', str(link))\n",
    "    link = url + link.group()[1:-1]  # link == 'https://public.psp.cz/en/sqw/phlasa.sqw?o=8&l=en&pg=1'\n",
    "    \n",
    "    r = requests.get(link)\n",
    "    soup = BeautifulSoup(r.content.decode('windows-1252', 'ignore'), 'html.parser')\n",
    "    ahrefs.clear()\n",
    "    \n",
    "    for link in soup.find_all('a'):\n",
    "        ahrefs.append(link.get('href'))\n",
    "\n",
    "    pg_list = []\n",
    "    for elem in ahrefs:\n",
    "        if elem.startswith('phlasa.sqw?o=8&l=en&pg='):\n",
    "            pg_list.append(int(elem.split('phlasa.sqw?o=8&l=en&pg=')[1]))\n",
    "\n",
    "    for i in range(max(pg_list) + 1):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        url = 'https://public.psp.cz/en/sqw/phlasa.sqw?o=8&l=en&pg=' + str(i)\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.content.decode('windows-1252', 'ignore'), 'html.parser')\n",
    "        ahrefs.clear()\n",
    "\n",
    "        # Step three\n",
    "        # Creating Votings data\n",
    "        for tr in soup.find_all('table')[0].find_all('tr'):\n",
    "            tds = []\n",
    "            for td in tr.find_all('td'):\n",
    "        #         display(td)\n",
    "                tds.append(td)\n",
    "            if not tds:\n",
    "                continue\n",
    "            # Meeting\n",
    "            meeting = tds.pop(0)\n",
    "            meeting = int(meeting.text)\n",
    "            # ID\n",
    "            id = tds.pop(0)\n",
    "            id = str(str(id.find('a').get('href')).split('hlasy.sqw?g=', 1)[1])[:-5]\n",
    "            # Topic\n",
    "            tds.remove(tds[0])\n",
    "            \n",
    "            topic = tds.pop(0).text.replace('\\u00D8', '\\u0158').replace('\\u00E8', '\\u010D').replace('\\xa0', ' ').replace('\\u00F8', '\\u0159').replace('\\u00EC', '\\u00E8')\n",
    "            # Date\n",
    "            date = tds.pop(0).text.replace('\\xa0', '')\n",
    "            # Result\n",
    "            result = tds.pop(0).text.replace('\\u00D8', '\\u0158').replace('\\u00E8', '\\u010D').replace('\\xa0', ' ').replace('\\u00F8', '\\u0159').replace('\\u00EC', '\\u00E8')\n",
    "            if result == 'Přijato':\n",
    "                result = 'Accepted'\n",
    "            elif result == 'Zamítnuto':\n",
    "                result = 'Denied'\n",
    "            elif result == 'Přijato (zmatečné)':  \n",
    "                result = 'Accepted (invalid)'  # objection received\n",
    "            elif result == 'Zamítnuto (zmatečné)':  \n",
    "                result = 'Denied (invalid)'\n",
    "            elif result == 'Přijato (přijata námitka)':  \n",
    "                result = 'Accepted (objection received)'\n",
    "            elif result == 'Zamítnuto (přijata námitka)':  \n",
    "                result = 'Denied (objection received)'\n",
    "#             vote_df.append([id, meeting, topic, date, result])\n",
    "            vote_list.append([id, meeting, topic, date, result])\n",
    "            # Step four\n",
    "            # Creating result data\n",
    "            vot_id = str(id)\n",
    "#             display(id)\n",
    "            url = 'https://public.psp.cz/en/sqw/hlasy.sqw?g=' + id + '&l=en'\n",
    "            try:\n",
    "                r = requests.get(url)\n",
    "            except:\n",
    "                continue\n",
    "            soup = BeautifulSoup(r.content.decode('windows-1252', 'ignore'), 'html.parser')\n",
    "            uls = soup.find_all('ul', {'class':'results'})\n",
    "\n",
    "            for ul in uls:\n",
    "                for li in ul.find_all('li'):\n",
    "                    name = li.find('a').text.replace('\\u00D8', '\\u0158').replace('\\u00E8', '\\u010D').replace('\\xa0', ' ').replace('\\u00F8', '\\u0159').replace('\\u00EC', '\\u00E8')\n",
    "                    id = str(li.find('a').get('href').split('id=', 1)[1])[:4]\n",
    "                    result = li.find('span').text\n",
    "                    if result == 'A':\n",
    "                        result = 1\n",
    "                    elif result == 'N':\n",
    "                        result = -1\n",
    "                    elif result == 'Z':\n",
    "                        result = 0\n",
    "                    elif result == 'M' or result == '0':\n",
    "                        result = -2\n",
    "                    results_list.append([id, vot_id, name, result])\n",
    "    # Step five\n",
    "    # Creating Depute data\n",
    "    url = 'https://public.psp.cz/en/sqw/hlasy.sqw?g=' + vote_list[0][0] + '&l=en'\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content.decode('windows-1252', 'ignore'), 'html.parser')\n",
    "    uls = soup.find_all('ul', {'class':'results'})\n",
    "        \n",
    "    for ul in uls:\n",
    "        for li in ul.find_all('li'):\n",
    "            name = li.find('a').text.replace('\\u00D8', '\\u0158').replace('\\u00E8', '\\u010D').replace('\\xa0', ' ').replace('\\u00F8', '\\u0159').replace('\\u00EC', '\\u00E8')\n",
    "            id = str(li.find('a').get('href').split('id=', 1)[1])[:4]\n",
    "            if id == '6165':  # speaker exeption. His page is changed\n",
    "                deput_list.append([id, name, 'ANO 2011', '26.10.2013'])  \n",
    "                continue\n",
    "            dep = Deputy(str(name),str(id))\n",
    "            if len(dep.polit_group) > 1:\n",
    "#                 print([dep.id, dep.name, dep.polit_group, dep.member_from])\n",
    "                for idx, pgroup in enumerate(set(dep.polit_group)):\n",
    "                    deput_list.append([dep.id, dep.name, pgroup, dep.member_from[idx]])\n",
    "            else:\n",
    "#                 print([dep.id, dep.name, dep.polit_group[0], dep.member_from])\n",
    "                deput_list.append([dep.id, dep.name, dep.polit_group[0], dep.member_from[0]])    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here we start scraping the data. \n",
    "# url with a form\n",
    "url = 'https://www.psp.cz/en/sqw/hlasovani.sqw?o=8'\n",
    "vote_list = []\n",
    "deput_list = []\n",
    "results_list = []\n",
    "\n",
    "download_data(url, vote_list, deput_list, results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(results_list, columns=['ID', 'Vote_id', 'Name', 'Result'])\n",
    "result_df.to_csv('result.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_df = pd.DataFrame(vote_list, columns=['ID', 'Name', 'Date', 'Result'])\n",
    "vote_df.to_csv('votes.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deput_df = pd.DataFrame(deput_list, columns=['ID', 'Name', 'Politic group', 'Member from'])\n",
    "deput_df.to_csv('deputies.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6983 entries, 0 to 6982\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   ID       6983 non-null   object\n",
      " 1   Vote_id  6983 non-null   int64 \n",
      " 2   Name     6983 non-null   object\n",
      " 3   Date     6983 non-null   object\n",
      " 4   Result   6983 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 272.9+ KB\n"
     ]
    }
   ],
   "source": [
    "vote_df.info()\n",
    "# result_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see depute who change his parlamentary club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Politic group</th>\n",
       "      <th>Member from</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>Jaroslav Foldyna</td>\n",
       "      <td>Political group Czech Social Democratic Party</td>\n",
       "      <td>25.2.2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>Jaroslav Foldyna</td>\n",
       "      <td>Political group Freedom and Direct Democracy</td>\n",
       "      <td>7.4.2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name                                  Politic group  \\\n",
       "ID                                                                      \n",
       "5911  Jaroslav Foldyna  Political group Czech Social Democratic Party   \n",
       "5911  Jaroslav Foldyna   Political group Freedom and Direct Democracy   \n",
       "\n",
       "     Member from  \n",
       "ID                \n",
       "5911   25.2.2020  \n",
       "5911    7.4.2020  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = deput_df[deput_df.duplicated(['Name'], keep=False)]\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-191742f037bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvote_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Vote_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m ) -> \"DataFrame\":\n\u001b[1;32m---> 73\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# to avoid incompat dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;31m# If argument passed to validate,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1144\u001b[0m                     \u001b[0minferred_right\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstring_types\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minferred_left\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m                 ):\n\u001b[1;32m-> 1146\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m             \u001b[1;31m# datetimelikes must match exactly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on int64 and object columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "result = pd.merge(vote_df, result_df, on=['ID', 'Vote_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
